# Crawl4AI Configuration Reference Guide

This document provides a comprehensive explanation of all configuration parameters available in the Crawl4AI scraper framework. The configuration file (in YAML or JSON format) controls every aspect of the scraping process, from targeting URLs to handling authentication, navigation, data extraction, proxy usage, and LLM-powered features.

## Table of Contents
1. [Basic Configuration](#basic-configuration)
2. [Browser and Request Settings](#browser-and-request-settings)
3. [Authentication and Login](#authentication-and-login)
4. [Navigation and Pagination](#navigation-and-pagination)
5. [Extraction Selectors](#extraction-selectors)
6. [Output Configuration](#output-configuration)
7. [Proxy Configuration](#proxy-configuration)
8. [LLM Selector Generation](#llm-selector-generation)
9. [Advanced Features](#advanced-features)
10. [Complete Configuration Example](#complete-configuration-example)

## Basic Configuration

These are the essential parameters that define the target of your scraping operation.

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `url` | String | The base URL to start scraping from | `"https://example.com/products"` |
| `session` | String | Name for the browser session (for cookie persistence) | `"default"` |
| `full_page` | Boolean | Whether to extract the entire page content instead of specific elements | `false` |

```yaml
# Minimal configuration example
url: "https://example.com/products"
session: "ecommerce_session"
full_page: false
```

## Browser and Request Settings

These settings control how the browser interacts with the website.

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `headers` | Object | HTTP headers to send with requests | See example below |
| `render_js` | Boolean | Whether to render JavaScript (uses Playwright) | `true` |
| `stealth_mode` | Boolean | Enable techniques to avoid bot detection | `true` |
| `timeout` | Number | Request timeout in milliseconds | `30000` |
| `wait_for` | String or Number | Element selector to wait for, or time in milliseconds | `"div.products"` or `5000` |
| `visible` | Boolean | Make the browser visible (for debugging) | `false` |

```yaml
# Browser settings example
headers:
  User-Agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36"
  Accept: "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"
  Referer: "https://example.com"
  Accept-Language: "en-US,en;q=0.9"

render_js: true
stealth_mode: true
timeout: 30000
wait_for: "div.content-loaded"
```

## Authentication and Login

Configure login procedures for websites that require authentication.

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `login.enabled` | Boolean | Whether login is required | `true` |
| `login.url` | String | URL of the login page | `"https://example.com/login"` |
| `login.actions` | Array | Sequence of actions to perform for login | See example below |
| `login.success_indicator` | String | CSS selector that indicates successful login | `".user-avatar"` |

Each action in the `login.actions` array can have the following properties:

| Action Property | Type | Description | Example |
|----------------|------|-------------|---------|
| `type` | String | Type of action: `"fill"`, `"click"`, `"wait"` | `"fill"` |
| `selector` | String | CSS selector for the element | `"input[name='username']"` |
| `value` | String | Value to fill in form fields (for `"fill"` type) | `"myusername"` |
| `duration` | Number | Time to wait in seconds (for `"wait"` type) | `2` |
| csrf_field | String | The name of the input field or cookie containing the CSRF tokene.g., "csrfmiddlewaretoken", "csrf_token", "_csrf"
| csrf_source | String | Where to find the CSRF token | "html", "cookie", or "header"

```yaml
# Login configuration example
login:
  enabled: true
  url: "https://example.com/login"
  # CSRF token configuration
  csrf_field: "csrfmiddlewaretoken"  # Name of the input field containing the token
  csrf_source: "html"                # Where to find the token: "html", "cookie", or "header"
  # Actions to perform for login
  actions:
    - type: fill
      selector: "input[name='username']"
      value: "myusername"
    - type: fill
      selector: "input[name='password']"
      value: "mypassword"
    - type: click
      selector: "button[type='submit']"
  success_indicator: ".dashboard-welcome"
```

## Navigation and Pagination

Control how the scraper navigates through the website structure.

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `navigation_type` | String | Type of navigation: `"pagination"`, `"links"`, `"api"`, or `"scroll"` | `"pagination"` |
| `pagination` | Object | Configuration for paginated navigation | See below |
| `link_selector` | String | CSS selector for links to follow (for `"links"` navigation type) | `"a.article-title"` |
| `max_links` | Number | Maximum number of links to follow (for `"links"` navigation type) | `10` |
| `endpoints` | Array | List of API endpoints to call (for `"api"` navigation type) | See example below |
| `scroll` | Object | Configuration for scroll-based navigation | See example below |

### Pagination Configuration

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `pagination.param` | String | URL parameter for page number | `"page"` |
| `pagination.start` | Number | Starting page number | `1` |
| `pagination.end` | Number | Ending page number | `5` |
| `pagination.step` | Number | Step size between pages | `1` |
| `pagination.appender` | String | Character used to append page parameter | `"&"` |
| `pagination.stop_if_empty` | Boolean | Whether to stop if a page returns no results | `true` |

### API Endpoints Configuration

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `endpoint.url` | String | URL of the API endpoint | `"https://api.example.com/products"` |
| `endpoint.method` | String | HTTP method: `"GET"`, `"POST"`, etc. | `"GET"` |
| `endpoint.params` | Object | Query parameters to include | `{"limit": 100, "offset": 0}` |

### Scroll Configuration

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `scroll.max_scrolls` | Number | Maximum number of scroll operations | `10` |
| `scroll.scroll_delay` | Number | Delay between scrolls in seconds | `2` |
| `scroll.item_selector` | String | CSS selector for items to extract | `"div.product-card"` |
| `scroll.min_items` | Number | Minimum number of items to collect before stopping | `100` |

```yaml
# Pagination navigation example
navigation_type: "pagination"
pagination:
  param: "page"
  start: 1
  end: 10
  step: 1
  appender: "&"
  stop_if_empty: true

# Link following example
navigation_type: "links"
link_selector: "a.article-title"
max_links: 20

# API navigation example
navigation_type: "api"
endpoints:
  - url: "https://api.example.com/products"
    method: "GET"
    params:
      limit: 100
      offset: 0
  - url: "https://api.example.com/reviews"
    method: "GET"

# Infinite scroll example
navigation_type: "scroll"
scroll:
  max_scrolls: 10
  scroll_delay: 2
  item_selector: "div.product-card"
  min_items: 100
```

## Extraction Selectors

Define what data to extract from the pages.

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| |`extract` | Object | Definition of data elements to extract | See example below |

Each selector in the `extract` object can have the following properties:

| Selector Property | Type | Description | Example |
|-------------------|------|-------------|---------|
| `type` | String | Type of selector: `"css"`, `"xpath"`, or `"group"` | `"css"` |
| `query` | String | CSS or XPath query | `"h1.product-title"` |
| `multiple` | Boolean | Whether to extract multiple elements | `false` |
| `attribute` | String | HTML attribute to extract (if any) | `"href"` |
| `container` | String | CSS selector for the container (for `"group"` type)  `"div.product-card"` |
| `fields` | Object | Field selectors within a group | See example below |

```yaml
# Simple extraction example: Simple extraction is designed for extracting individual elements that appear once
# (or a specific number of times) on a page. Each selector corresponds to a distinct piece of information.
extract:
  title:
    type: "css"
    query: "h1.product-title"
    multiple: false
  price:
    type: "css"
    query: "span.price"
    multiple: false
  description:
    type: "css"
    query: "div.product-description"
    multiple: false
  image_url:
    type: "css"
    query: "img.product-image"
    attribute: "src"
    multiple: false

# Group extraction example: Group extraction is designed for repeated patterns of data,
#like a list of products on a search results page, where each item has the same structure but different content.
extract:
  products:
    type: "group"
    multiple: true
    container: "div.product-card"
    fields:
      name:
        type: "css"
        query: "h3.product-name"
        multiple: false
      price:
        type: "css"
        query: "span.price"
        multiple: false
      image:
        type: "css"
        query: "img.product-image"
        attribute: "src"
        multiple: false
```

## Output Configuration

Control the format and location of extracted data.

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `output_format` | String | Output format: `"json"`, `"csv"`, `"yaml"`, or `"markdown"` | `"json"` |
| `output_dir` | String | Directory to save output files | `"output"` |
| `merge_results` | Boolean | Whether to merge results from multiple pages | `true` |

```yaml
# Output configuration example
output_format: "json"
output_dir: "scraped_data/products"
merge_results: true
```

## Proxy Configuration

Configure proxy rotation to avoid IP blocking.

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `proxy.enabled` | Boolean | Whether to use proxies | `true` |
| `proxy.proxies` | Array | List of proxy servers to use | See example below |
| `proxy.proxy_file` | String | Path to file containing proxy list | `"proxies.json"` |
| `proxy.proxy_api_url` | String | URL of API providing proxies | `"https://proxy-provider.com/api/proxies"` |
| `proxy.proxy_api_key` | String | API key for proxy service | `"your_api_key"` |
| `proxy.rotation_strategy` | String | Strategy for rotating proxies: `"round_robin"`, `"random"`, or `"performance"` | `"round_robin"` |
| `proxy.test_url` | String | URL to test proxy connectivity | `"https://httpbin.org/ip"` |
| `proxy.max_failures` | Number | Maximum failures before banning a proxy | `3` |
| `proxy.min_delay_between_rotations` | Number | Minimum delay between proxy rotations in seconds | `5` |
| `proxy.test_on_start` | Boolean | Whether to test all proxies on startup | `true` |

```yaml
# Proxy configuration example
proxy:
  enabled: true
  proxies:
    - host: "proxy1.example.com"
      port: 8080
      username: "user1"
      password: "pass1"
    - host: "proxy2.example.com"
      port: 8080
    - "http://user3:pass3@proxy3.example.com:8080"
    - "proxy4.example.com:8080"
  rotation_strategy: "performance"
  test_url: "https://httpbin.org/ip"
  max_failures: 3
  min_delay_between_rotations: 10
  test_on_start: true
```

## LLM Selector Generation

Configure AI-powered selector generation using large language models.

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `llm_selectors.enabled` | Boolean | Whether to use LLM for selector generation | `true` |
| `llm_selectors.llm_provider` | String | LLM provider: `"anthropic"` or `"openai"` | `"anthropic"` |
| `llm_selectors.llm_model` | String | Model to use | `"claude-3-haiku-20240307"` |
| `llm_selectors.llm_api_key` | String | API key for LLM service | `"your_api_key"` |
| `llm_selectors.max_html_length` | Number | Maximum HTML length to send to LLM | `12000` |
| `llm_selectors.use_cache` | Boolean | Whether to cache generated selectors | `true` |
| `llm_selectors.cache_dir` | String | Directory for caching selectors | `"selector_cache"` |
| `llm_selectors.generate_on_start` | Boolean | Whether to generate selectors on startup | `true` |
| `extraction_spec` | Object | Specification of what data to extract | See example below |

```yaml
# LLM selector configuration example
llm_selectors:
  enabled: true
  llm_provider: "anthropic"
  llm_model: "claude-3-haiku-20240307"
  max_html_length: 12000
  use_cache: true
  cache_dir: "selector_cache"
  generate_on_start: true

# Extraction specification for LLM
extraction_spec:
  # Simple fields
  title: null
  price: null
  description: null

  # Groups with fields
  products:
    - name
    - price
    - image_url

  related_items:
    - title
    - url
```

## Advanced Features

Additional settings for specialized scraping scenarios.

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `request_delay` | Number | Delay between requests in seconds | `3` |
| `retry_count` | Number | Number of retries for failed requests | `3` |
| `retry_delay` | Number | Delay between retries in seconds | `5` |
| `user_agent_rotation` | Boolean | Whether to rotate user agents | `true` |
| `user_agents` | Array | List of user agents to rotate through | See example below |
| `cookies_file` | String | Path to file containing cookies | `"cookies.json"` |
| `robots_txt` | Boolean | Whether to respect robots.txt | `true` |
| `initial_visit_required` | Boolean | Whether to visit main page first to set cookies | `true` |
| `date_range` | Object | Date range for time-based scraping | See example below |
| `parse_json` | Boolean | Whether to parse API responses as JSON | `true` |

```yaml
# Advanced features example
request_delay: 3
retry_count: 3
retry_delay: 5
user_agent_rotation: true
user_agents:
  - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36"
  - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15"
  - "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
cookies_file: "session_cookies.json"
robots_txt: true
initial_visit_required: true

# Date range configuration (for time-based APIs)
date_range:
  start_date: "01-01-2024"
  end_date: "31-01-2024"
  format: "DD-MM-YYYY"
```

## Complete Configuration Example

Here's a comprehensive example that combines multiple features:

```yaml
# Target URL and session
url: "https://example-store.com/products"
session: "ecommerce_session"

# Browser settings
headers:
  User-Agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36"
  Accept: "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"
  Referer: "https://example.com"
render_js: true
stealth_mode: true
timeout: 30000

# Login configuration
login:
  enabled: true
  url: "https://example-store.com/login"
  actions:
    - type: fill
      selector: "input#email"
      value: "youremail@example.com"
    - type: fill
      selector: "input#password"
      value: "yourpassword"
    - type: click
      selector: "button[type='submit']"
  success_indicator: ".user-avatar"

# Navigation settings
navigation_type: "pagination"
pagination:
  param: "page"
  start: 1
  end: 5
  appender: "&"
  stop_if_empty: true

# Proxy configuration
proxy:
  enabled: true
  proxies:
    - host: "proxy1.example.com"
      port: 8080
      username: "user1"
      password: "pass1"
    - "proxy2.example.com:8080"
  rotation_strategy: "performance"
  test_url: "https://httpbin.org/ip"
  max_failures: 3
  min_delay_between_rotations: 10
  test_on_start: true

# LLM selector generation
llm_selectors:
  enabled: true
  llm_provider: "anthropic"
  llm_model: "claude-3-haiku-20240307"
  use_cache: true
  generate_on_start: true

# Extraction specification for LLM
extraction_spec:
  products:
    - name
    - price
    - original_price
    - discount_percent
    - image_url
    - description
    - rating
    - review_count

# Manual extraction configuration (used as fallback if LLM disabled)
extract:
  products:
    type: "group"
    multiple: true
    container: "div.product-card"
    fields:
      name:
        type: "css"
        query: "h3.product-name"
      price:
        type: "css"
        query: "span.price"
      image:
        type: "css"
        query: "img.product-image"
        attribute: "src"

# Output settings
output_format: "json"
output_dir: "scraped_data/products"
merge_results: true

# Advanced settings
request_delay: 3
retry_count: 3
initial_visit_required: true
```

## Environment Variables

The following environment variables can be used to override configuration values:

| Environment Variable | Description |
|----------------------|-------------|
| `CRAWL4AI_API_KEY` | API key for Crawl4AI service |
| `ANTHROPIC_API_KEY` | API key for Anthropic Claude |
| `OPENAI_API_KEY` | API key for OpenAI |
| `CRAWL4AI_API_URL` | Base URL for Crawl4AI API |
| `PROXY_LIST_PATH` | Path to proxy list file |

## Command Line Options

The following command line options can be used to override configuration values:

```bash
python crawl4ai_main.py -c config.yaml --proxy --llm --proxy-file proxies.txt --llm-key your_api_key
```

| Option | Description |
|--------|-------------|
| `-c, --config` | Path to configuration file |
| `-o, --output` | Output file name |
| `-u, --url` | Override URL in configuration |
| `-v, --verbose` | Enable verbose logging |
| `--proxy` | Enable proxy rotation |
| `--llm` | Enable LLM selector generation |
| `--proxy-file` | Path to proxy list file |
| `--llm-key` | API key for LLM service |
| `--test-selectors` | Test selectors and display results without scraping |

## Tips for Specific Website Types

### E-commerce Websites
- Use `navigation_type: "pagination"`
- Enable JavaScript rendering
- Extract product details, prices, ratings, and images
- Consider using LLM selector generation for product cards

### News/Content Websites
- Use `navigation_type: "links"` to follow article links
- Extract article text, author, date, and categories
- Output to markdown for better readability

### API-based Websites
- Use `navigation_type: "api"` with multiple endpoints
- Set appropriate headers for authentication
- Enable `parse_json: true`

### Infinite Scroll Websites
- Use `navigation_type: "scroll"`
- Set appropriate `max_scrolls` and `scroll_delay`
- Define `item_selector` for the repeated elements

### Sites with Bot Protection
- Enable `stealth_mode: true`
- Configure proxy rotation with multiple proxies
- Add random delays between requests
- Use a variety of user agents